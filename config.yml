#
## Configuration
#
# Model Defaults
# Prompts (system and user messges)


model:
  name: "alcf:mistralai/Mistral-7B-Instruct-v0.3"
  temperature: 0.7

  
prompts:
  system_message: |
    You are a helpful assistant that summarizes text in bullet points and expands on them using your broader knowledge. Name this result 'augmented_chunk'.
  user_message: |
    Given the following chunk of text, please:

    1. Summarize the text in bullet points.
    2. Expand on the summary using your parametric knowledge.

    Chunk:
    {chunk}

    Return the result as plain text labeled 'augmented_chunk:' at the start.
  system_message_2: |
    You are a helpful assistant that generates exactly ONE multiple-choice question based on the provided text (augmented_chunk). The question must have 5 possible answers, numbered 1 to 5. Exactly one of these 5 choices is correct. Mark the correct choice with '(*)' at the end for later grading.
  user_message_2: |
    Below is some content called augmented_chunk.
    Please:
    1) Create exactly one multiple-choice question that can be answered by the augmented_chunk.
    2) Provide five distinct options (1 to 5) as answers.
    3) Mark the correct answer with '(*)' at the end of that particular option.

    Constraints:
    - The question and answers must be self-contained and understandable without referencing the chunk.
    - Do not mention 'chunk' or 'augmented_chunk' or 'article' or 'study' in the final output.

    augmented_chunk:
    {augmented_chunk}
  system_message_3: |
    You are a helpful assistant that evaluates how well an answer matches the question in context of the augmented_chunk. Return your answer and a score from 1 to 10. Output MUST BE VALID JSON in the form:
    {{"answer":"...","score":9}}
  user_message_3: |
    augmented_chunk:
    {augmented_chunk}

    question:
    {generated_question}

    Please provide:
    1. An appropriate answer to the multiple-choice question above. Your answer should identify which option is correct and why.
    2. A single integer 'score' from 1 to 10 for how well the answer addresses the question based on the augmented_chunk.

    Output must be valid JSON in the form:
    {{"answer":"...","score":9}}

